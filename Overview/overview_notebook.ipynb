{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fazer um compilado organizando todas as informações que juntamos até agora:\n",
    "- Descrição do problema\n",
    "- Descrição do dataset\n",
    "    - Desbalanceamento das classes\n",
    "    - Proporção se manteve nos conjuntos de treinamento/teste.\n",
    "- Curvas de performance do treinamento do classficador\n",
    "- Matrizes de confusão do modelo original\n",
    "- Problema do viés foi encontrado\n",
    "- Histogramas de cor por classe\n",
    "- Plot t-SNE do dataset\n",
    "- Identificação do viés no background\n",
    "- Falar sobre o artigo original do PlantiVillage que já identificava esse problema\n",
    "- Falar sobre o artigo dos 8px (background)\n",
    "- Treinamento de modelos alternativos(1)\n",
    "    - Sem background\n",
    "        - Falar sobre a pequena queda na performance e fazer novo plot t-SNE e matriz de confusão\n",
    "    - 8pxs\n",
    "        - Falar sobre o desbalanceamento e entender que na verdade o modelo não aprendeu nada\n",
    "        - Critica ao artigo dos 8pxs atestada pela matriz de confusão e pelo plot t-SNE.\n",
    "- Identificação dos problemas de cor e exposição\n",
    "- Introdução sobre os métodos de correção de cor (CC) e correção de exposição (CE), explicar sobre a influência do background nesses métodos\n",
    "- Treinamento de modelos alternativos(2)\n",
    "        - Sem backgound + CC\n",
    "        - Sem background + CE\n",
    "        - Sem background + CC + CE\n",
    "        - Sem background + CE + CC\n",
    "        - CE + CC\n",
    "        - CC + CE\n",
    "        - CC\n",
    "        - CE\n",
    "    - Falar sobre as diferenças de performance em cada um dos modelos (talvez um subconjunto deles)\n",
    "    - Fazer matrizes de confusão e plot t-SNE\n",
    "    - Identificar imagens que foram de uma classe para outra do modelo original para o modelo com pior performance\n",
    "        - Utilizar heatmaps para explicitar que estava sendo olhado o background nesses momentos\n",
    "    - Pensar sobre como identificar que estava sendo olhado cor e exposição em alguns desses dados e que, após o processamento, o modelo n teria mais essas infos e, portanto, errou.\n",
    "    - Talvez olhar métricas relacionadas à coesão dos clusters.\n",
    "\n",
    "\n",
    "- Juntando esses histogramas, matrizes de confusão, resultados, plots t-SNE, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dado que temos os datasets processados e queremos provar que o original tinha os vieses:\n",
    "\n",
    "Step 1: Analyze Bias Using One Model and Two Datasets\n",
    "\n",
    "* Explainability Analysis: Utilize tools such as saliency maps, Grad-CAM to visualize and compare how the model’s focus on image features changes between the original and processed images. This will help identify whether the model is inappropriately relying on certain features that may contribute to bias.\n",
    "* Confidence Level Measurement: Evaluate how the confidence levels of the model's predictions vary between the datasets. A notable decrease in prediction confidence when known biased features are modified or removed indicates that the model's performance was previously dependent on these features.\n",
    "* Error Analysis: Assess and compare the error rates and types (such as false positives and false negatives) across both datasets. This step will highlight which features were essential for the original model's decisions and how their modification impacts model accuracy and reliability.\n",
    "* Correlation and Causation Analysis: Conduct statistical analyses, such as calculating mutual information or Pearson correlation, to quantitatively measure the relationship between specific features (e.g., white balance, exposure) and the model’s outputs or errors. High correlation values would confirm a significant influence of these features on model decisions.\n",
    "    * To perform a Correlation and Causation Analysis focusing on white balance and camera exposure using machine learning approaches and histogram analysis, given the lack of metadata, you can take the following steps:\n",
    "    Estimating White Balance and Camera Exposure\n",
    "\n",
    "    1. Machine Learning Models for White Balance Estimation:\n",
    "\n",
    "        Data Preparation: Collect a dataset of images where the white balance settings are known or can be reasonably assumed (e.g., images taken in controlled lighting conditions). Alternatively, manually adjust white balance on a subset of images to create a labeled dataset.\n",
    "        Feature Extraction: Use color features of the images, such as the average, median, and variance of RGB channels, as input features for the model.\n",
    "        Model Training: Train a regression or classification model to predict the white balance setting based on these features. Techniques like support vector machines, decision trees, or neural networks can be suitable depending on the dataset size and complexity.\n",
    "\n",
    "    2. Histogram Analysis for Camera Exposure Estimation:\n",
    "\n",
    "        Histogram Calculation: Compute the histograms of the image luminance (brightness) or the individual RGB channels. Analyze the spread and peaks of the histograms:\n",
    "            Underexposed images generally have a peak towards the left side of the histogram.\n",
    "            Overexposed images have a peak towards the right side.\n",
    "        Feature Engineering: Create features based on histogram characteristics, such as skewness, kurtosis, and the position of the peak brightness.\n",
    "        Model Training: Train a model to estimate exposure levels based on these histogram features. Regression models could predict an exposure index, while classification models might categorize images as underexposed, correctly exposed, or overexposed.\n",
    "\n",
    "    Performing Correlation and Causation Analysis\n",
    "\n",
    "    1. Correlation Analysis:\n",
    "\n",
    "        Statistical Measures: Once you have predictions or estimates for white balance and exposure from your models, calculate Pearson or Spearman correlation coefficients between these features and the outputs of your main model (e.g., class probabilities, confidence scores).\n",
    "        Visualization: Create visualizations like scatter plots or correlation matrices to better understand the relationships between image features and model decisions.\n",
    "\n",
    "    2. Causal Analysis:\n",
    "\n",
    "        Adjust Image Properties: Manually adjust the white balance and exposure of a set of test images based on the predictions of your models, creating variants of each image with different settings.\n",
    "        Counterfactual Analysis: Use these variants to see how the changes in white balance and exposure affect the model's predictions. This can be approached by predicting class labels for each variant and observing the differences.\n",
    "        Causal Impact Analysis: Employ statistical techniques to analyze the impact of these changes on model predictions, establishing a causal relationship if one exists.\n",
    "\n",
    "    3. Reporting Results:\n",
    "\n",
    "        Statistical Reporting: Include confidence intervals and p-values in your analysis to assess the significance of your findings.\n",
    "        Comprehensive Documentation: Document all the methodologies, from data preparation through model training to analysis, ensuring transparency and reproducibility.\n",
    "\n",
    "    Using these approaches, you can rigorously assess how white balance and camera exposure influence your model's predictions without relying on metadata. This will help you establish whether these features contribute to bias in your model's decisions and provide a basis for further improving the model's fairness and accuracy.\n",
    "\n",
    "Step 2: Develop a Less Biased Model\n",
    "* Model Training: Upon identifying a processed dataset that exhibits reduced bias based on your initial analysis, train a new model using this dataset. This step is crucial to evaluate if removing biased features leads to a model that is not only less biased but also performs well on relevant tasks.\n",
    "* Enhanced t-SNE Analysis: Apply t-SNE analysis to visualize the new model's data clustering. Measure and quantify changes in the cluster formation, purity, and separation by using statistical tests or cluster quality metrics like the Silhouette score. This analysis will help determine if the model now better distinguishes between classes based on relevant features rather than biased ones.\n",
    "\n",
    "Conclusion and Future Considerations\n",
    "* Document Findings and Improvements: Thoroughly document all methodologies, results, and statistical analyses. Clearly demonstrate how each step contributes to identifying and reducing bias, thereby supporting the validity of your improved model.\n",
    "* Acknowledge Limitations: Conclude with a discussion of the study's limitations. Recognize that while significant improvements have been made, the potential for other unexplored biases remains. This acknowledgment is crucial for fostering an ongoing dialogue about enhancing model fairness and reliability.\n",
    "* Recommendations for Future Work: Suggest directions for further research, such as exploring additional biases, applying the methodology to other models or data types, or developing new tools for bias detection and mitigation.\n",
    "\n",
    "\n",
    "## Nessa abordagem, fica faltando uma coisa central: provar que a queda de perfomance é oriunda da remoção do vies e não da característica correta do dataset. Para fazer isso, podemos utilizar um pouco do gradcam no seguinte sentido:\n",
    "1. Pega 1 imagem original, vê os resultados\n",
    "2. Pega essa mesma imagem processada, vê que os resultados ficaram piores\n",
    "3. Faz o gradcam dessa imagem,\n",
    "4. Identifica que antes o modelo estava olhando para coisas que não deveria\n",
    "\n",
    "Talvez, gerar um saliency map agragado por classe...\n",
    "\n",
    "Mas, acho que faz muito mais sentido ter conseguido observar uma relação espúria entre white balance e exposição com relação ao output do modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
