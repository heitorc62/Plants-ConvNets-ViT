PyTorch Version:  1.12.1
Torchvision Version:  0.13.1
The selected device is: cuda:0
VGG(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU(inplace=True)
    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU(inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): ReLU(inplace=True)
    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): ReLU(inplace=True)
    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (39): ReLU(inplace=True)
    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): ReLU(inplace=True)
    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))
  (classifier): Sequential(
    (0): Linear(in_features=25088, out_features=4096, bias=True)
    (1): ReLU(inplace=True)
    (2): Dropout(p=0.5, inplace=False)
    (3): Linear(in_features=4096, out_features=4096, bias=True)
    (4): ReLU(inplace=True)
    (5): Dropout(p=0.5, inplace=False)
    (6): Linear(in_features=4096, out_features=39, bias=True)
  )
)
Params to learn:
	 features.0.weight
	 features.0.bias
	 features.1.weight
	 features.1.bias
	 features.3.weight
	 features.3.bias
	 features.4.weight
	 features.4.bias
	 features.7.weight
	 features.7.bias
	 features.8.weight
	 features.8.bias
	 features.10.weight
	 features.10.bias
	 features.11.weight
	 features.11.bias
	 features.14.weight
	 features.14.bias
	 features.15.weight
	 features.15.bias
	 features.17.weight
	 features.17.bias
	 features.18.weight
	 features.18.bias
	 features.20.weight
	 features.20.bias
	 features.21.weight
	 features.21.bias
	 features.24.weight
	 features.24.bias
	 features.25.weight
	 features.25.bias
	 features.27.weight
	 features.27.bias
	 features.28.weight
	 features.28.bias
	 features.30.weight
	 features.30.bias
	 features.31.weight
	 features.31.bias
	 features.34.weight
	 features.34.bias
	 features.35.weight
	 features.35.bias
	 features.37.weight
	 features.37.bias
	 features.38.weight
	 features.38.bias
	 features.40.weight
	 features.40.bias
	 features.41.weight
	 features.41.bias
	 classifier.0.weight
	 classifier.0.bias
	 classifier.3.weight
	 classifier.3.bias
	 classifier.6.weight
	 classifier.6.bias
Epoch 0/29
----------
PyTorch Version:  1.12.1
Torchvision Version:  0.13.1
The selected device is: cuda:0
VGG(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU(inplace=True)
    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU(inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): ReLU(inplace=True)
    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): ReLU(inplace=True)
    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (39): ReLU(inplace=True)
    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): ReLU(inplace=True)
    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))
  (classifier): Sequential(
    (0): Linear(in_features=25088, out_features=4096, bias=True)
    (1): ReLU(inplace=True)
    (2): Dropout(p=0.5, inplace=False)
    (3): Linear(in_features=4096, out_features=4096, bias=True)
    (4): ReLU(inplace=True)
    (5): Dropout(p=0.5, inplace=False)
    (6): Linear(in_features=4096, out_features=39, bias=True)
  )
)
Params to learn:
	 classifier.6.weight
	 classifier.6.bias
Epoch 0/29
----------
train Loss: 1.0619 Acc: 0.7017
val Loss: 0.5207 Acc: 0.8443

Epoch 1/29
----------
train Loss: 0.8008 Acc: 0.7602
val Loss: 0.4659 Acc: 0.8583

Epoch 2/29
----------
train Loss: 0.5264 Acc: 0.8440
val Loss: 0.1819 Acc: 0.9458

Epoch 1/29
----------
train Loss: 0.7774 Acc: 0.7676
val Loss: 0.4414 Acc: 0.8705

Epoch 3/29
----------
train Loss: 0.7549 Acc: 0.7722
val Loss: 0.3820 Acc: 0.8805

Epoch 4/29
----------
train Loss: 0.7383 Acc: 0.7773
val Loss: 0.4190 Acc: 0.8700

Epoch 5/29
----------
train Loss: 0.2269 Acc: 0.9285
val Loss: 0.1343 Acc: 0.9563

Epoch 2/29
----------
train Loss: 0.7371 Acc: 0.7770
val Loss: 0.4473 Acc: 0.8598

Epoch 6/29
----------
train Loss: 0.7306 Acc: 0.7793
val Loss: 0.4029 Acc: 0.8721

Epoch 7/29
----------
train Loss: 0.7273 Acc: 0.7783
val Loss: 0.3893 Acc: 0.8810

Epoch 8/29
----------
train Loss: 0.1761 Acc: 0.9445
val Loss: 0.1122 Acc: 0.9650

Epoch 3/29
----------
train Loss: 0.7200 Acc: 0.7818
val Loss: 0.3884 Acc: 0.8824

Epoch 9/29
----------
train Loss: 0.7229 Acc: 0.7834
val Loss: 0.3799 Acc: 0.8824

Epoch 10/29
----------
train Loss: 0.7169 Acc: 0.7831
train Loss: 0.1472 Acc: 0.9536
val Loss: 0.3686 Acc: 0.8878

Epoch 11/29
----------
val Loss: 0.0902 Acc: 0.9731

Epoch 4/29
----------
train Loss: 0.7262 Acc: 0.7823
val Loss: 0.3789 Acc: 0.8830

Epoch 12/29
----------
train Loss: 0.7140 Acc: 0.7857
val Loss: 0.3773 Acc: 0.8883

Epoch 13/29
----------
train Loss: 0.1347 Acc: 0.9580
train Loss: 0.7214 Acc: 0.7829
val Loss: 0.0805 Acc: 0.9748

Epoch 5/29
----------
val Loss: 0.4306 Acc: 0.8722

Epoch 14/29
----------
train Loss: 0.7150 Acc: 0.7854
val Loss: 0.4376 Acc: 0.8774

Epoch 15/29
----------
train Loss: 0.7171 Acc: 0.7853
val Loss: 0.3642 Acc: 0.8833

Epoch 16/29
----------
train Loss: 0.1140 Acc: 0.9642
val Loss: 0.0730 Acc: 0.9781

Epoch 6/29
----------
train Loss: 0.7192 Acc: 0.7843
val Loss: 0.3590 Acc: 0.8873

Epoch 17/29
----------
train Loss: 0.7179 Acc: 0.7839
val Loss: 0.4052 Acc: 0.8830

Epoch 18/29
----------
train Loss: 0.7152 Acc: 0.7849
val Loss: 0.3554 Acc: 0.8881

Epoch 19/29
----------
train Loss: 0.1087 Acc: 0.9654
val Loss: 0.0614 Acc: 0.9806

Epoch 7/29
----------
train Loss: 0.7188 Acc: 0.7852
val Loss: 0.4138 Acc: 0.8812

Epoch 20/29
----------
train Loss: 0.7249 Acc: 0.7831
val Loss: 0.3665 Acc: 0.8896

Epoch 21/29
----------
train Loss: 0.7172 Acc: 0.7845
val Loss: 0.3593 Acc: 0.8885

Epoch 22/29
----------
train Loss: 0.0978 Acc: 0.9687
val Loss: 0.0646 Acc: 0.9798

Epoch 8/29
----------
train Loss: 0.7103 Acc: 0.7866
val Loss: 0.3947 Acc: 0.8801

Epoch 23/29
----------
train Loss: 0.7114 Acc: 0.7867
val Loss: 0.3683 Acc: 0.8895

Epoch 24/29
----------
train Loss: 0.7058 Acc: 0.7890
train Loss: 0.0951 Acc: 0.9695
val Loss: 0.4299 Acc: 0.8815

Epoch 25/29
----------
val Loss: 0.0833 Acc: 0.9739

Epoch 9/29
----------
train Loss: 0.7164 Acc: 0.7879
val Loss: 0.3702 Acc: 0.8883

Epoch 26/29
----------
train Loss: 0.7091 Acc: 0.7873
val Loss: 0.3678 Acc: 0.8869

Epoch 27/29
----------
train Loss: 0.0877 Acc: 0.9724
train Loss: 0.7043 Acc: 0.7889
val Loss: 0.0741 Acc: 0.9773

Epoch 10/29
----------
val Loss: 0.3331 Acc: 0.8933

Epoch 28/29
----------
train Loss: 0.7217 Acc: 0.7864
val Loss: 0.3504 Acc: 0.8882

Epoch 29/29
----------
train Loss: 0.7088 Acc: 0.7889
val Loss: 0.3608 Acc: 0.8869

Training complete in 369m 50s
Best val Acc: 0.893327
#############################################################################################################
train Loss: 0.0865 Acc: 0.9720
val Loss: 0.0627 Acc: 0.9816

Epoch 11/29
----------
train Loss: 0.0794 Acc: 0.9742
val Loss: 0.0627 Acc: 0.9809

Epoch 12/29
----------
train Loss: 0.0778 Acc: 0.9754
val Loss: 0.0515 Acc: 0.9839

Epoch 13/29
----------
train Loss: 0.0733 Acc: 0.9764
val Loss: 0.0483 Acc: 0.9858

Epoch 14/29
----------
train Loss: 0.0699 Acc: 0.9772
val Loss: 0.0517 Acc: 0.9855

Epoch 15/29
----------
train Loss: 0.0672 Acc: 0.9788
val Loss: 0.0516 Acc: 0.9849

Epoch 16/29
----------
train Loss: 0.0635 Acc: 0.9795
val Loss: 0.0582 Acc: 0.9826

Epoch 17/29
----------
train Loss: 0.0670 Acc: 0.9788
val Loss: 0.0427 Acc: 0.9875

Epoch 18/29
----------
train Loss: 0.0624 Acc: 0.9800
val Loss: 0.0551 Acc: 0.9849

Epoch 19/29
----------
train Loss: 0.0636 Acc: 0.9803
val Loss: 0.0495 Acc: 0.9858

Epoch 20/29
----------
train Loss: 0.0585 Acc: 0.9808
val Loss: 0.0511 Acc: 0.9854

Epoch 21/29
----------
train Loss: 0.0560 Acc: 0.9819
val Loss: 0.0498 Acc: 0.9865

Epoch 22/29
----------
train Loss: 0.0573 Acc: 0.9821
val Loss: 0.0466 Acc: 0.9866

Epoch 23/29
----------
train Loss: 0.0562 Acc: 0.9822
val Loss: 0.0470 Acc: 0.9867

Epoch 24/29
----------
train Loss: 0.0536 Acc: 0.9829
val Loss: 0.0493 Acc: 0.9847

Epoch 25/29
----------
train Loss: 0.0545 Acc: 0.9828
val Loss: 0.0478 Acc: 0.9837

Epoch 26/29
----------
train Loss: 0.0501 Acc: 0.9838
val Loss: 0.0492 Acc: 0.9850

Epoch 27/29
----------
train Loss: 0.0512 Acc: 0.9831
val Loss: 0.0522 Acc: 0.9848

Epoch 28/29
----------
train Loss: 0.0483 Acc: 0.9842
val Loss: 0.0485 Acc: 0.9851

Epoch 29/29
----------
train Loss: 0.0482 Acc: 0.9849
val Loss: 0.0487 Acc: 0.9867

Training complete in 703m 13s
Best val Acc: 0.987466
#############################################################################################################
