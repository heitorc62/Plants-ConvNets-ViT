PyTorch Version:  1.12.1
Torchvision Version:  0.13.1
The selected device is: cuda:1
VGG(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU(inplace=True)
    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU(inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): ReLU(inplace=True)
    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): ReLU(inplace=True)
    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (39): ReLU(inplace=True)
    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): ReLU(inplace=True)
    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))
  (classifier): Sequential(
    (0): Linear(in_features=25088, out_features=4096, bias=True)
    (1): ReLU(inplace=True)
    (2): Dropout(p=0.5, inplace=False)
    (3): Linear(in_features=4096, out_features=4096, bias=True)
    (4): ReLU(inplace=True)
    (5): Dropout(p=0.5, inplace=False)
    (6): Linear(in_features=4096, out_features=39, bias=True)
  )
)
Params to learn:
	 classifier.6.weight
	 classifier.6.bias
Epoch 0/99
----------
last_layer ---> train Loss: 1.0648 Acc: 0.7021
last_layer ---> val Loss: 0.5175 Acc: 0.8507

Epoch 1/99
----------
last_layer ---> train Loss: 0.8127 Acc: 0.7553
last_layer ---> val Loss: 0.4847 Acc: 0.8508

Epoch 2/99
----------
last_layer ---> train Loss: 0.7640 Acc: 0.7695
last_layer ---> val Loss: 0.4306 Acc: 0.8629

Epoch 3/99
----------
last_layer ---> train Loss: 0.7563 Acc: 0.7725
last_layer ---> val Loss: 0.4309 Acc: 0.8700

Epoch 4/99
----------
last_layer ---> train Loss: 0.7506 Acc: 0.7724
last_layer ---> val Loss: 0.4066 Acc: 0.8766

Epoch 5/99
----------
last_layer ---> train Loss: 0.7409 Acc: 0.7775
last_layer ---> val Loss: 0.4098 Acc: 0.8754

Epoch 6/99
----------
last_layer ---> train Loss: 0.7360 Acc: 0.7769
last_layer ---> val Loss: 0.4061 Acc: 0.8735

Epoch 7/99
----------
last_layer ---> train Loss: 0.7300 Acc: 0.7797
last_layer ---> val Loss: 0.4277 Acc: 0.8768

Epoch 8/99
----------
last_layer ---> train Loss: 0.7218 Acc: 0.7825
last_layer ---> val Loss: 0.4066 Acc: 0.8777

Epoch 9/99
----------
last_layer ---> train Loss: 0.7361 Acc: 0.7774
last_layer ---> val Loss: 0.3650 Acc: 0.8850

Epoch 10/99
----------
last_layer ---> train Loss: 0.7257 Acc: 0.7814
last_layer ---> val Loss: 0.3810 Acc: 0.8839

Epoch 11/99
----------
last_layer ---> train Loss: 0.7257 Acc: 0.7814
last_layer ---> val Loss: 0.3676 Acc: 0.8858

Epoch 12/99
----------
last_layer ---> train Loss: 0.7270 Acc: 0.7818
last_layer ---> val Loss: 0.3735 Acc: 0.8815

Epoch 13/99
----------
last_layer ---> train Loss: 0.7180 Acc: 0.7834
last_layer ---> val Loss: 0.3458 Acc: 0.8891

Epoch 14/99
----------
last_layer ---> train Loss: 0.7183 Acc: 0.7858
last_layer ---> val Loss: 0.3890 Acc: 0.8829

Epoch 15/99
----------
last_layer ---> train Loss: 0.7048 Acc: 0.7882
last_layer ---> val Loss: 0.3480 Acc: 0.8910

Epoch 16/99
----------
last_layer ---> train Loss: 0.7091 Acc: 0.7874
last_layer ---> val Loss: 0.3471 Acc: 0.8975

Epoch 17/99
----------
last_layer ---> train Loss: 0.7166 Acc: 0.7848
last_layer ---> val Loss: 0.3831 Acc: 0.8828

Epoch 18/99
----------
last_layer ---> train Loss: 0.7131 Acc: 0.7858
last_layer ---> val Loss: 0.3913 Acc: 0.8851

Epoch 19/99
----------
last_layer ---> train Loss: 0.7171 Acc: 0.7835
last_layer ---> val Loss: 0.3612 Acc: 0.8867

Epoch 20/99
----------
last_layer ---> train Loss: 0.7069 Acc: 0.7885
last_layer ---> val Loss: 0.3660 Acc: 0.8891

Epoch 21/99
----------
last_layer ---> train Loss: 0.7163 Acc: 0.7851
last_layer ---> val Loss: 0.3614 Acc: 0.8892

Epoch 22/99
----------
last_layer ---> train Loss: 0.7117 Acc: 0.7839
last_layer ---> val Loss: 0.3490 Acc: 0.8876

Epoch 23/99
----------
last_layer ---> train Loss: 0.7172 Acc: 0.7869
last_layer ---> val Loss: 0.3398 Acc: 0.8957

Epoch 24/99
----------
last_layer ---> train Loss: 0.7153 Acc: 0.7857
last_layer ---> val Loss: 0.3685 Acc: 0.8841

Epoch 25/99
----------
last_layer ---> train Loss: 0.7155 Acc: 0.7875
last_layer ---> val Loss: 0.3682 Acc: 0.8853

Epoch 26/99
----------
last_layer ---> train Loss: 0.7091 Acc: 0.7877
last_layer ---> val Loss: 0.3822 Acc: 0.8865

Epoch 27/99
----------
last_layer ---> train Loss: 0.7078 Acc: 0.7863
last_layer ---> val Loss: 0.3732 Acc: 0.8869

Epoch 28/99
----------
last_layer ---> train Loss: 0.7102 Acc: 0.7864
last_layer ---> val Loss: 0.3657 Acc: 0.8898

Epoch 29/99
----------
last_layer ---> train Loss: 0.7191 Acc: 0.7838
last_layer ---> val Loss: 0.4381 Acc: 0.8799

Epoch 30/99
----------
last_layer ---> train Loss: 0.7106 Acc: 0.7869
last_layer ---> val Loss: 0.3503 Acc: 0.8919

Epoch 31/99
----------
last_layer ---> train Loss: 0.7015 Acc: 0.7898
last_layer ---> val Loss: 0.3494 Acc: 0.8905

Epoch 32/99
----------
last_layer ---> train Loss: 0.7123 Acc: 0.7878
last_layer ---> val Loss: 0.3550 Acc: 0.8929

Epoch 33/99
----------
last_layer ---> train Loss: 0.7138 Acc: 0.7903
last_layer ---> val Loss: 0.4022 Acc: 0.8830

Epoch 34/99
----------
last_layer ---> train Loss: 0.7037 Acc: 0.7890
last_layer ---> val Loss: 0.4370 Acc: 0.8762

Epoch 35/99
----------
last_layer ---> train Loss: 0.7005 Acc: 0.7916
last_layer ---> val Loss: 0.3917 Acc: 0.8929

Epoch 36/99
----------
last_layer ---> train Loss: 0.7173 Acc: 0.7858
last_layer ---> val Loss: 0.3634 Acc: 0.8905

Epoch 37/99
----------
last_layer ---> train Loss: 0.7155 Acc: 0.7859
last_layer ---> val Loss: 0.3379 Acc: 0.8944

Epoch 38/99
----------
last_layer ---> train Loss: 0.7137 Acc: 0.7870
last_layer ---> val Loss: 0.3409 Acc: 0.8924

Epoch 39/99
----------
last_layer ---> train Loss: 0.7148 Acc: 0.7864
last_layer ---> val Loss: 0.3409 Acc: 0.8921

Epoch 40/99
----------
last_layer ---> train Loss: 0.7069 Acc: 0.7885
last_layer ---> val Loss: 0.3818 Acc: 0.8861

Epoch 41/99
----------
last_layer ---> train Loss: 0.7017 Acc: 0.7907
last_layer ---> val Loss: 0.3331 Acc: 0.8972

Epoch 42/99
----------
last_layer ---> train Loss: 0.7089 Acc: 0.7903
last_layer ---> val Loss: 0.4031 Acc: 0.8875

Epoch 43/99
----------
last_layer ---> train Loss: 0.7022 Acc: 0.7893
last_layer ---> val Loss: 0.3481 Acc: 0.8948

Epoch 44/99
----------
last_layer ---> train Loss: 0.7146 Acc: 0.7890
last_layer ---> val Loss: 0.3575 Acc: 0.8926

Epoch 45/99
----------
last_layer ---> train Loss: 0.7114 Acc: 0.7883
last_layer ---> val Loss: 0.3511 Acc: 0.8902

Epoch 46/99
----------
last_layer ---> train Loss: 0.6997 Acc: 0.7920
last_layer ---> val Loss: 0.3396 Acc: 0.8946

Epoch 47/99
----------
last_layer ---> train Loss: 0.7097 Acc: 0.7887
last_layer ---> val Loss: 0.3216 Acc: 0.8989

Epoch 48/99
----------
last_layer ---> train Loss: 0.7085 Acc: 0.7869
last_layer ---> val Loss: 0.3807 Acc: 0.8846

Epoch 49/99
----------
last_layer ---> train Loss: 0.7069 Acc: 0.7889
last_layer ---> val Loss: 0.3439 Acc: 0.8884

Epoch 50/99
----------
last_layer ---> train Loss: 0.7083 Acc: 0.7889
last_layer ---> val Loss: 0.3440 Acc: 0.8931

Epoch 51/99
----------
last_layer ---> train Loss: 0.7057 Acc: 0.7906
last_layer ---> val Loss: 0.3368 Acc: 0.8957

Epoch 52/99
----------
last_layer ---> train Loss: 0.7043 Acc: 0.7919
last_layer ---> val Loss: 0.4454 Acc: 0.8859

Epoch 53/99
----------
last_layer ---> train Loss: 0.6973 Acc: 0.7907
last_layer ---> val Loss: 0.3623 Acc: 0.8912

Epoch 54/99
----------
last_layer ---> train Loss: 0.7086 Acc: 0.7902
last_layer ---> val Loss: 0.3396 Acc: 0.9004

Epoch 55/99
----------
last_layer ---> train Loss: 0.6994 Acc: 0.7924
last_layer ---> val Loss: 0.3284 Acc: 0.8984

Epoch 56/99
----------
last_layer ---> train Loss: 0.7001 Acc: 0.7923
last_layer ---> val Loss: 0.3604 Acc: 0.8946

Epoch 57/99
----------
last_layer ---> train Loss: 0.7038 Acc: 0.7897
last_layer ---> val Loss: 0.3514 Acc: 0.8903

Epoch 58/99
----------
last_layer ---> train Loss: 0.7035 Acc: 0.7893
last_layer ---> val Loss: 0.3494 Acc: 0.8943

Epoch 59/99
----------
last_layer ---> train Loss: 0.7009 Acc: 0.7895
last_layer ---> val Loss: 0.3512 Acc: 0.8920

Epoch 60/99
----------
last_layer ---> train Loss: 0.7093 Acc: 0.7869
last_layer ---> val Loss: 0.3408 Acc: 0.8966

Epoch 61/99
----------
last_layer ---> train Loss: 0.7047 Acc: 0.7910
last_layer ---> val Loss: 0.3680 Acc: 0.8901

Epoch 62/99
----------
last_layer ---> train Loss: 0.6997 Acc: 0.7914
last_layer ---> val Loss: 0.3702 Acc: 0.8874

Epoch 63/99
----------
last_layer ---> train Loss: 0.7039 Acc: 0.7923
last_layer ---> val Loss: 0.3311 Acc: 0.8976

Epoch 64/99
----------
last_layer ---> train Loss: 0.7067 Acc: 0.7904
last_layer ---> val Loss: 0.3481 Acc: 0.8933

Epoch 65/99
----------
last_layer ---> train Loss: 0.7038 Acc: 0.7918
last_layer ---> val Loss: 0.3519 Acc: 0.8917

Epoch 66/99
----------
last_layer ---> train Loss: 0.7076 Acc: 0.7908
last_layer ---> val Loss: 0.3463 Acc: 0.8938

Epoch 67/99
----------
last_layer ---> train Loss: 0.7081 Acc: 0.7900
last_layer ---> val Loss: 0.3671 Acc: 0.8881

Epoch 68/99
----------
last_layer ---> train Loss: 0.7095 Acc: 0.7885
last_layer ---> val Loss: 0.3467 Acc: 0.8945

Epoch 69/99
----------
last_layer ---> train Loss: 0.7134 Acc: 0.7885
last_layer ---> val Loss: 0.3287 Acc: 0.8939

Epoch 70/99
----------
last_layer ---> train Loss: 0.7109 Acc: 0.7885
last_layer ---> val Loss: 0.3291 Acc: 0.8971

Epoch 71/99
----------
last_layer ---> train Loss: 0.7032 Acc: 0.7915
last_layer ---> val Loss: 0.3525 Acc: 0.8913

Epoch 72/99
----------
last_layer ---> train Loss: 0.7081 Acc: 0.7903
last_layer ---> val Loss: 0.3561 Acc: 0.8894

Epoch 73/99
----------
last_layer ---> train Loss: 0.7077 Acc: 0.7875
last_layer ---> val Loss: 0.3420 Acc: 0.8908

Epoch 74/99
----------
last_layer ---> train Loss: 0.7009 Acc: 0.7921
last_layer ---> val Loss: 0.3342 Acc: 0.8954

Epoch 75/99
----------
last_layer ---> train Loss: 0.6987 Acc: 0.7924
last_layer ---> val Loss: 0.3655 Acc: 0.8855

Epoch 76/99
----------
last_layer ---> train Loss: 0.7110 Acc: 0.7888
last_layer ---> val Loss: 0.3482 Acc: 0.8886

Epoch 77/99
----------
last_layer ---> train Loss: 0.7037 Acc: 0.7915
last_layer ---> val Loss: 0.3709 Acc: 0.8897

Epoch 78/99
----------
last_layer ---> train Loss: 0.7130 Acc: 0.7880
last_layer ---> val Loss: 0.3408 Acc: 0.8880

Epoch 79/99
----------
last_layer ---> train Loss: 0.7086 Acc: 0.7898
last_layer ---> val Loss: 0.4214 Acc: 0.8858

Epoch 80/99
----------
last_layer ---> train Loss: 0.7075 Acc: 0.7890
last_layer ---> val Loss: 0.3591 Acc: 0.8893

Epoch 81/99
----------
last_layer ---> train Loss: 0.7195 Acc: 0.7871
last_layer ---> val Loss: 0.3496 Acc: 0.8940

Epoch 82/99
----------
last_layer ---> train Loss: 0.7060 Acc: 0.7916
last_layer ---> val Loss: 0.3191 Acc: 0.9024

Epoch 83/99
----------
last_layer ---> train Loss: 0.7040 Acc: 0.7900
last_layer ---> val Loss: 0.3254 Acc: 0.8994

Epoch 84/99
----------
last_layer ---> train Loss: 0.7034 Acc: 0.7908
last_layer ---> val Loss: 0.3346 Acc: 0.8964

Epoch 85/99
----------
last_layer ---> train Loss: 0.7049 Acc: 0.7906
last_layer ---> val Loss: 0.3765 Acc: 0.8857

Epoch 86/99
----------
last_layer ---> train Loss: 0.7059 Acc: 0.7905
last_layer ---> val Loss: 0.3585 Acc: 0.8913

Epoch 87/99
----------
last_layer ---> train Loss: 0.7046 Acc: 0.7908
last_layer ---> val Loss: 0.4094 Acc: 0.8849

Epoch 88/99
----------
last_layer ---> train Loss: 0.6953 Acc: 0.7967
last_layer ---> val Loss: 0.3469 Acc: 0.8891

Epoch 89/99
----------
last_layer ---> train Loss: 0.7097 Acc: 0.7906
last_layer ---> val Loss: 0.3314 Acc: 0.8984

Epoch 90/99
----------
last_layer ---> train Loss: 0.6980 Acc: 0.7935
last_layer ---> val Loss: 0.3248 Acc: 0.8946

Epoch 91/99
----------
last_layer ---> train Loss: 0.7133 Acc: 0.7907
last_layer ---> val Loss: 0.3511 Acc: 0.8931

Epoch 92/99
----------
last_layer ---> train Loss: 0.7031 Acc: 0.7910
last_layer ---> val Loss: 0.3189 Acc: 0.9005

Epoch 93/99
----------
last_layer ---> train Loss: 0.7077 Acc: 0.7904
last_layer ---> val Loss: 0.3258 Acc: 0.8980

Epoch 94/99
----------
last_layer ---> train Loss: 0.7006 Acc: 0.7921
last_layer ---> val Loss: 0.3554 Acc: 0.8903

Epoch 95/99
----------
last_layer ---> train Loss: 0.6974 Acc: 0.7925
last_layer ---> val Loss: 0.3611 Acc: 0.8962

Epoch 96/99
----------
last_layer ---> train Loss: 0.6995 Acc: 0.7913
last_layer ---> val Loss: 0.3690 Acc: 0.8862

Epoch 97/99
----------
last_layer ---> train Loss: 0.7009 Acc: 0.7923
last_layer ---> val Loss: 0.3373 Acc: 0.8968

Epoch 98/99
----------
last_layer ---> train Loss: 0.7084 Acc: 0.7907
last_layer ---> val Loss: 0.3167 Acc: 0.9037

Epoch 99/99
----------
last_layer ---> train Loss: 0.6985 Acc: 0.7909
last_layer ---> val Loss: 0.3511 Acc: 0.8921

last_layer ---> Training complete in 307m 22s
last_layer ---> Best val Acc: 0.903697
############################################## last_layer ###############################################################
